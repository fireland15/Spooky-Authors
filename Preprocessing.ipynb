{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def make_labels(data):\n",
    "    a2c = {'EAP': 0, 'HPL' : 1, 'MWS' : 2}\n",
    "    labels = np.array([a2c[a] for a in data.author])\n",
    "    labels = to_categorical(labels)\n",
    "    return labels\n",
    "\n",
    "def get_text_only(data):\n",
    "    return data[\"text\"]\n",
    "\n",
    "def calc_metrics(x, y_true, y_pred):\n",
    "    return classification_report(y_true, y_pred)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def calc_confusion_matrix(y_true, y_pred):\n",
    "    return confusion_matrix(np.argmax(y_true, axis=1), np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def run(load_func, preprocess_func, create_model_func):\n",
    "    print(\"Loading data\")\n",
    "    full_data = load_func()\n",
    "    \n",
    "    print(\"Getting labels\")\n",
    "    labels = make_labels(full_data)    \n",
    "    \n",
    "    print(\"Preprocessing\")\n",
    "    data = preprocess_func(get_text_only(full_data))\n",
    "    \n",
    "    input_dim = max([max(x) for x in data]) + 1\n",
    "\n",
    "    print(\"Creating model\")\n",
    "    model = create_model_func(input_dim)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)\n",
    "    \n",
    "    print(\"Training model\")\n",
    "    model.fit(x_train, y_train,\n",
    "                 batch_size=16,\n",
    "                 validation_data=(x_test, y_test),\n",
    "                 epochs=64,\n",
    "                 verbose=2,\n",
    "                 callbacks=[EarlyStopping(patience=2, monitor='val_loss')])\n",
    "    print(\"Training complete\")\n",
    "    \n",
    "    print(\"Testing model\")\n",
    "    y_pred = model.predict_classes(x_test)\n",
    "    y_pred = to_categorical(y_pred, num_classes=3)\n",
    "    \n",
    "    print(\"Test results\")  \n",
    "    print(\"metrics\")\n",
    "    print(calc_metrics(x_test, y_test, y_pred))\n",
    "    print(\"confusion matrix\")\n",
    "    print(calc_confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_training_data():\n",
    "    return pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, GlobalAveragePooling1D, Embedding\n",
    "from keras.models import Sequential\n",
    "\n",
    "def create_simple_model(input_dim, embedding_dims=20, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=input_dim, output_dim=embedding_dims))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Forrest\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# removes stop words from the sentences in text\n",
    "def remove_stops(text):\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    return [\" \".join([word for word in nltk.word_tokenize(words) if word not in stops]) for words in text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# converts the sentences in text into a sequence of numbers\n",
    "def convert_to_sequences(text, filters, to_lower):\n",
    "    tokenizer = Tokenizer(filters=filters, lower=to_lower, split=\" \", char_level=False)\n",
    "    tokenizer.fit_on_texts(text);\n",
    "    return tokenizer.texts_to_sequences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def pad_data(text):\n",
    "    maxlen = np.amax([len(x) for x in text], axis=0)\n",
    "    return pad_sequences(sequences=text, maxlen=maxlen)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Getting labels\n",
      "Preprocessing\n",
      "Creating model\n",
      "Training model\n",
      "Train on 15663 samples, validate on 3916 samples\n",
      "Epoch 1/64\n",
      " - 7s - loss: 1.0859 - acc: 0.4054 - val_loss: 1.0879 - val_acc: 0.3935\n",
      "Epoch 2/64\n",
      " - 6s - loss: 1.0785 - acc: 0.4072 - val_loss: 1.0755 - val_acc: 0.3940\n",
      "Epoch 3/64\n",
      " - 6s - loss: 1.0599 - acc: 0.4175 - val_loss: 1.0544 - val_acc: 0.4035\n",
      "Epoch 4/64\n",
      " - 6s - loss: 1.0241 - acc: 0.4801 - val_loss: 1.0112 - val_acc: 0.5061\n",
      "Epoch 5/64\n",
      " - 6s - loss: 0.9727 - acc: 0.5602 - val_loss: 0.9617 - val_acc: 0.5580\n",
      "Epoch 6/64\n",
      " - 6s - loss: 0.9129 - acc: 0.6331 - val_loss: 0.9091 - val_acc: 0.6182\n",
      "Epoch 7/64\n",
      " - 6s - loss: 0.8514 - acc: 0.6876 - val_loss: 0.8634 - val_acc: 0.7188\n",
      "Epoch 8/64\n",
      " - 6s - loss: 0.7929 - acc: 0.7237 - val_loss: 0.8143 - val_acc: 0.6691\n",
      "Epoch 9/64\n",
      " - 6s - loss: 0.7398 - acc: 0.7481 - val_loss: 0.7717 - val_acc: 0.7227\n",
      "Epoch 10/64\n",
      " - 6s - loss: 0.6896 - acc: 0.7705 - val_loss: 0.7412 - val_acc: 0.6994\n",
      "Epoch 11/64\n",
      " - 6s - loss: 0.6448 - acc: 0.7867 - val_loss: 0.7096 - val_acc: 0.7099\n",
      "Epoch 12/64\n",
      " - 6s - loss: 0.6031 - acc: 0.8051 - val_loss: 0.6742 - val_acc: 0.7436\n",
      "Epoch 13/64\n",
      " - 6s - loss: 0.5659 - acc: 0.8163 - val_loss: 0.6443 - val_acc: 0.7646\n",
      "Epoch 14/64\n",
      " - 6s - loss: 0.5310 - acc: 0.8288 - val_loss: 0.6194 - val_acc: 0.7735\n",
      "Epoch 15/64\n",
      " - 6s - loss: 0.4990 - acc: 0.8426 - val_loss: 0.5994 - val_acc: 0.7758\n",
      "Epoch 16/64\n",
      " - 6s - loss: 0.4685 - acc: 0.8553 - val_loss: 0.5774 - val_acc: 0.7883\n",
      "Epoch 17/64\n",
      " - 6s - loss: 0.4393 - acc: 0.8670 - val_loss: 0.5664 - val_acc: 0.7863\n",
      "Epoch 18/64\n",
      " - 6s - loss: 0.4134 - acc: 0.8762 - val_loss: 0.5402 - val_acc: 0.8016\n",
      "Epoch 19/64\n",
      " - 6s - loss: 0.3893 - acc: 0.8855 - val_loss: 0.5278 - val_acc: 0.8026\n",
      "Epoch 20/64\n",
      " - 6s - loss: 0.3668 - acc: 0.8915 - val_loss: 0.5175 - val_acc: 0.8026\n",
      "Epoch 21/64\n",
      " - 6s - loss: 0.3466 - acc: 0.9016 - val_loss: 0.4980 - val_acc: 0.8164\n",
      "Epoch 22/64\n",
      " - 6s - loss: 0.3263 - acc: 0.9063 - val_loss: 0.4872 - val_acc: 0.8182\n",
      "Epoch 23/64\n",
      " - 7s - loss: 0.3086 - acc: 0.9121 - val_loss: 0.4809 - val_acc: 0.8159\n",
      "Epoch 24/64\n",
      " - 6s - loss: 0.2912 - acc: 0.9179 - val_loss: 0.4764 - val_acc: 0.8235\n",
      "Epoch 25/64\n",
      " - 6s - loss: 0.2743 - acc: 0.9249 - val_loss: 0.4674 - val_acc: 0.8195\n",
      "Epoch 26/64\n",
      " - 6s - loss: 0.2588 - acc: 0.9298 - val_loss: 0.4527 - val_acc: 0.8256\n",
      "Epoch 27/64\n",
      " - 6s - loss: 0.2455 - acc: 0.9334 - val_loss: 0.4525 - val_acc: 0.8202\n",
      "Epoch 28/64\n",
      " - 6s - loss: 0.2330 - acc: 0.9379 - val_loss: 0.4408 - val_acc: 0.8294\n",
      "Epoch 29/64\n",
      " - 6s - loss: 0.2197 - acc: 0.9437 - val_loss: 0.4363 - val_acc: 0.8340\n",
      "Epoch 30/64\n",
      " - 6s - loss: 0.2081 - acc: 0.9471 - val_loss: 0.4280 - val_acc: 0.8325\n",
      "Epoch 31/64\n",
      " - 6s - loss: 0.1970 - acc: 0.9507 - val_loss: 0.4310 - val_acc: 0.8338\n",
      "Epoch 32/64\n",
      " - 6s - loss: 0.1864 - acc: 0.9530 - val_loss: 0.4214 - val_acc: 0.8361\n",
      "Epoch 33/64\n",
      " - 6s - loss: 0.1775 - acc: 0.9554 - val_loss: 0.4172 - val_acc: 0.8378\n",
      "Epoch 34/64\n",
      " - 6s - loss: 0.1683 - acc: 0.9571 - val_loss: 0.4161 - val_acc: 0.8371\n",
      "Epoch 35/64\n",
      " - 6s - loss: 0.1594 - acc: 0.9605 - val_loss: 0.4131 - val_acc: 0.8320\n",
      "Epoch 36/64\n",
      " - 6s - loss: 0.1509 - acc: 0.9637 - val_loss: 0.4134 - val_acc: 0.8340\n",
      "Epoch 37/64\n",
      " - 6s - loss: 0.1446 - acc: 0.9653 - val_loss: 0.4277 - val_acc: 0.8228\n",
      "Training complete\n",
      "Testing model\n",
      "Test results\n",
      "metrics\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.91      0.83      1540\n",
      "          1       0.93      0.74      0.82      1121\n",
      "          2       0.84      0.79      0.82      1255\n",
      "\n",
      "avg / total       0.84      0.82      0.82      3916\n",
      "\n",
      "confusion matrix\n",
      "[[1403   26  111]\n",
      " [ 221  824   76]\n",
      " [ 228   32  995]]\n"
     ]
    }
   ],
   "source": [
    "def convert_to_sequence_and_pad(text):\n",
    "    return pad_data(convert_to_sequences(text, \"\", False))\n",
    "\n",
    "run(load_training_data, convert_to_sequence_and_pad, create_simple_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Attempted | acc | loss | val_acc | val_loss | epochs |\n",
    "|-----------|-----|------|---------|----------|--------|\n",
    "| Tokenize only | 0.9182 | 0.2822 | 0.8026 | 0.4854 | 25/64 |\n",
    "| Filter non alphanumeric (!@#$%^&*()-=_+,./<>?;:'\\\") | 0.9399 |0.1989 | 0.8292 | 0.4235 | 36/64|\n",
    "| texts_to_matrix insteadt of texts_to_sequences | 0.4054 | 1.0872 | 0.3961 | 1.0898 | 6/64 |\n",
    "| Filter like above without converting to lowercase | 0.9478 | 0.1815 | 0.8253 | 0.4169 | 35/64 |\n",
    "| Filter special chars and remove stop words | 0.9314 | 0.2331 | 0.8184 | 0.4475 | 22/64 |\n",
    "| Filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
